import os, sys, csv
import torch
from transformers import T5ForConditionalGeneration,T5Tokenizer
from experiment_impact_tracker.compute_tracker import ImpactTracker

log_prefix = './gen_power_log/'

# change this on each run
log_folder = '250_recipes_and_blocks/'

log_folder = log_prefix + log_folder

tracker = ImpactTracker(log_folder)
tracker.launch_impact_monitor()

# model_loc = ''
# num_of_examples = 0
seed = 42
class parainfer:

	def __init__(self):
		torch.manual_seed(1)
		if torch.cuda.is_available():
			torch.cuda.manual_seed_all(seed)
		print("Loading T5 model")
		self.model = T5ForConditionalGeneration.from_pretrained(model_loc)
		self.tokenizer = T5Tokenizer.from_pretrained('t5-base')
		self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
		self.model = self.model.to(self.device)
		print("T5 ready")

	def generate(self, sentence):
		sourcetext =  "paraphrase: " + sentence + " </s>"

		max_len = 256

		encoding = self.tokenizer.encode_plus(sourcetext, padding=True, return_tensors="pt")
		input_ids, attention_masks = encoding["input_ids"].to(self.device), encoding["attention_mask"].to(self.device)

		output = self.model.generate(
			input_ids=input_ids, attention_mask=attention_masks,
			do_sample=True,
			max_length=max_len,
			top_k=120,
			top_p=0.98,
			early_stopping=True,
			num_return_sequences=num_of_examples
		)
		
		final_outputs = []
		for item in output:
			sent = self.tokenizer.decode(item, skip_special_tokens=True, clean_up_tokenization_spaces=True)
			if sent.lower() != sentence.lower() and sent not in final_outputs:
				final_outputs.append(sent)

		return final_outputs



def writeFile(model, original_file, source_dest_file, target_dest_file):

	for row in original_file:

		source_line = row[0]
		target_line = row[1]
		
		# Every line generated by t5 will still have the same source
		source_out_line = [source_line]

		# Generate t5 paraphrases
		paraphrases = model.generate(source_line)

		# Add every line generated to the new training file 
		for line in paraphrases:
			#set target as paraphrase
			 target_out_line = [line]
			 # write original source
			 source_dest_file.writerow(source_out_line)
			 # write new target
			 target_dest_file.writerow(target_out_line)


def moveFile(original_file, source_dest_file, target_dest_file):

	for row in original_file:

		source_line = row[0]
		target_line = row[1]

		# write canonical line to training source file
		source_out_line = [source_line]
		source_dest_file.writerow(source_out_line)

		#write the original paraphrase to training target file
		target_out_line = [target_line]
		target_dest_file.writerow(target_out_line)



# done:

# domain_to_do = ['housing','basketball','social','calendar','publications','restaurants','blocks', 'recipes']
domain_to_do = ['blocks','recipes']

for domain in domain_to_do:
	
	num_of_examples = int(sys.argv[1])

	# domain = "housing"
	model_loc = '../../overnight_'+domain+'_model/'
	data_loc = '../../seq2seq_data/cannonical/test_only/'+domain+'/'
	# save_loc = '../../../overnight_seq2seq/cannonical/all_domains/'+ str(num_of_examples) + '_examples/' +'test_only/para_only/'+domain+'/data/'
	save_loc = '/media/chrissyp/data_drive/overnight_seq2seq/cannonical/all_domains/' + str(num_of_examples) + '_examples/' +'test_only/para_only/'+domain+'/data/'
	model = parainfer()


	if not os.path.exists(save_loc):
		os.makedirs(save_loc)


	print("Reading domain: " + domain)
	print("From: " + data_loc)
	print("Saving to: " + save_loc)
	print("Generating with " + str(num_of_examples) + " examples")


	training_source_file = csv.writer(open(save_loc + "train_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	training_target_file = csv.writer(open(save_loc + "train_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	validation_source_file = csv.writer(open(save_loc + "val_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	validation_target_file = csv.writer(open(save_loc + "val_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	testing_source_file = csv.writer(open(save_loc + "test_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	testing_target_file = csv.writer(open(save_loc + "test_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	train_file_string = data_loc + 'train.csv'
	val_file_string = data_loc + 'val.csv'
	test_file_string = data_loc + 'test.csv'


	train_file = csv.reader(open(train_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
	valid_file = csv.reader(open(val_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
	test_file = csv.reader(open(test_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)

	#skip the headers
	next(train_file)
	next(valid_file)
	next(test_file)


	# generate training data

	print("Generating Training data")

	writeFile(model, train_file, training_source_file, training_target_file)

	print("Finished Training data")
	print("Generating Validation data")

	moveFile(valid_file, validation_source_file, validation_target_file)

	print("Finished validation data")
	print("Moving over test data")

	moveFile(test_file, testing_source_file, testing_target_file)

	print("Finished " + domain)