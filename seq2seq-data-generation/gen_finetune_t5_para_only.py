import os, sys, csv
import torch
from transformers import T5ForConditionalGeneration,T5Tokenizer

# T5 model class
seed = 42
class parainfer:

	def __init__(self):
		torch.manual_seed(1)
		if torch.cuda.is_available():
			torch.cuda.manual_seed_all(seed)
		print("Loading T5 model")
		self.model = T5ForConditionalGeneration.from_pretrained(model_loc)
		self.tokenizer = T5Tokenizer.from_pretrained('t5-base')
		self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
		self.model = self.model.to(self.device)
		print("T5 ready")

	def generate(self, sentence):
		sourcetext =  "paraphrase: " + sentence + " </s>"

		max_len = 256

		encoding = self.tokenizer.encode_plus(sourcetext, padding=True, return_tensors="pt")
		input_ids, attention_masks = encoding["input_ids"].to(self.device), encoding["attention_mask"].to(self.device)

		output = self.model.generate(
			input_ids=input_ids, attention_mask=attention_masks,
			do_sample=True,
			max_length=max_len,
			top_k=120,
			top_p=0.98,
			early_stopping=True,
			num_return_sequences=num_of_examples
		)
		
		final_outputs = []
		for item in output:
			sent = self.tokenizer.decode(item, skip_special_tokens=True, clean_up_tokenization_spaces=True)
			if sent.lower() != sentence.lower() and sent not in final_outputs:
				final_outputs.append(sent)

		return final_outputs


# Paraphrase original utterances and write new training file
# model - (T5) model to use for paraphrasing
# original_file - train.csv for domain
# source_dest_file - canonical utterance train file
# target_dest_file - paraphrased utterance train file
def writeFile(model, original_file, source_dest_file, target_dest_file):

	for row in original_file:

		source_line = row[0]
		target_line = row[1] # Not used
		
		# Every line generated by t5 will still have the same source
		source_out_line = [source_line]

		# Generate t5 paraphrases
		paraphrases = model.generate(source_line)

		# Add every line generated to the new training file 
		for line in paraphrases:
			#set target as paraphrase
			 target_out_line = [line]
			 # write original source
			 source_dest_file.writerow(source_out_line)
			 # write new target
			 target_dest_file.writerow(target_out_line)

# Move val and test files
# original_file - val.csv or test.csv for domain
# source_dest_file - canonical utterance val/test file
# target_dest_file - human paraphrased val/test file
def moveFile(original_file, source_dest_file, target_dest_file):

	for row in original_file:

		source_line = row[0]
		target_line = row[1]

		# write canonical line to source file
		source_out_line = [source_line]
		source_dest_file.writerow(source_out_line)

		#write the original paraphrase to target file
		target_out_line = [target_line]
		target_dest_file.writerow(target_out_line)



# loop generation on all domains

domain_to_do = ['housing','basketball','social','calendar','publications','restaurants','blocks', 'recipes']

for domain in domain_to_do:

	# Number of examples to have (T5) model generate
	# Needs to be set before model instantiation
	num_of_examples = int(sys.argv[1])	

	
	model_loc = '../../overnight_'+domain+'_model/'
	data_loc = '../../seq2seq_data/cannonical/test_only/'+domain+'/'
	save_loc = '../../../overnight_seq2seq/cannonical/all_domains/'+ str(num_of_examples) + '_examples/' +'test_only/para_only/'+domain+'/data/'

	model = parainfer()


	# Make sure we have somewhere to save the data
	if not os.path.exists(save_loc):
		os.makedirs(save_loc)



	print(f"Reading domain: {domain}")
	print(f"From: {dat_loc}")
	print(f"Saving to: {save_loc}")
	print(f"Generating with {num_of_examples} examples")


	training_source_file = csv.writer(open(save_loc + "train_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	training_target_file = csv.writer(open(save_loc + "train_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	validation_source_file = csv.writer(open(save_loc + "val_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	validation_target_file = csv.writer(open(save_loc + "val_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	testing_source_file = csv.writer(open(save_loc + "test_cannonical.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)
	testing_target_file = csv.writer(open(save_loc + "test_paraphrase.txt", mode="w"), delimiter=',')#, quotechar='', quoting=csv.QUOTE_NONNUMERIC)

	train_file_string = data_loc + 'train.csv'
	val_file_string = data_loc + 'val.csv'
	test_file_string = data_loc + 'test.csv'


	train_file = csv.reader(open(train_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
	valid_file = csv.reader(open(val_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
	test_file = csv.reader(open(test_file_string, mode='r'), delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)

	#skip the headers ("Source","Target") in csv files
	next(train_file)
	next(valid_file)
	next(test_file)


	# generate training data

	print("Generating Training data")

	writeFile(model, train_file, training_source_file, training_target_file)

	print("Finished Training data")
	print("Generating Validation data")

	moveFile(valid_file, validation_source_file, validation_target_file)

	print("Finished validation data")
	print("Moving over test data")

	moveFile(test_file, testing_source_file, testing_target_file)

	print(f"Finished {domain}")